---
content_type: page
description: 'This section provides the second unit of the course: least squares,
  determinants, and eigenvalues.'
learning_resource_types: []
ocw_type: CourseSection
title: 'Unit II: Least Squares, Determinants and Eigenvalues'
uid: cf73d07a-c972-ab3c-450a-0f10d0be0664
video_metadata:
  youtube_id: null
---

« {{% resource_link f5c6f676-32a0-d7e7-bcdf-bc97569b662f "Previous" %}} | {{% resource_link fd8c8a4d-fa1b-e88c-ec23-abef203fca2a "Next" %}} »

{{< resource 8f4d1bf6-fe6c-33b9-3070-e3efc4cbb7df >}}

A graph and its edge-node incidence matrix.

Each component of a vector in R{{< sup "n" >}} indicates a distance along one of the coordinate axes. This practice of dissecting a vector into directional components is an important one. In particular, it leads to the "least squares" method of fitting curves to collections of data. This unit also introduces matrix _eigenvalues_ and _eigenvectors_. Many calculations become simpler when working with a basis of eigenvectors.

The _determinant_ of a matrix is a number characterizing that matrix. This value is useful for determining whether a matrix is singular, computing its inverse, and more.

Looking for something specific in this course? The {{% resource_link 754d6be4-ca3c-378b-6c8b-2e4a955ffe64 "Resource Index" %}} compiles links to most course resources in a single page.

« {{% resource_link f5c6f676-32a0-d7e7-bcdf-bc97569b662f "Previous" %}} | {{% resource_link fd8c8a4d-fa1b-e88c-ec23-abef203fca2a "Next" %}} »